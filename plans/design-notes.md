# Design Notes — Cross-Cutting Concerns

## Hook Handler Robustness (Self-Hosting Prerequisite)

When developing Konsolai with Claude running inside Konsolai itself, the hook handler becomes a critical path. If state tracking drifts (e.g., a hook event is dropped and Claude is reported as Idle when it's actually mid-tool-use), yolo modes can fire inappropriately — triple yolo could inject a prompt while Claude is writing code, corrupting the session.

### Failure Modes to Test

1. **Dropped hook events**: The Unix socket has a connection backlog limit. Under heavy tool use (rapid Read/Write cycles), events could queue up or be lost. The hook handler binary has a 10s timeout on the socket connection — if Konsolai is slow to accept, the handler exits and the event is gone.

2. **State machine desync**: `ClaudeProcess` derives state from hook events. If a `PreToolUse` event arrives but the corresponding `Stop` event is lost, the state machine is stuck in `Working` forever. Triple yolo never fires (safe failure), but the UI is wrong. Worse: if `Stop` arrives but `PreToolUse` was lost, the state machine thinks Claude is `Idle` during active tool use.

3. **Race between yolo action and state change**: The idle handler fires on a `QTimer::singleShot`. If a state change arrives between scheduling and execution, the lambda captures `this` but doesn't re-check state. The current code does re-check in `scheduleSuggestionFallback()` but not in the primary `QTimer::singleShot` paths.

4. **Hook handler process crashes**: The handler binary might segfault or be killed by OOM. Claude Code will still run, but Konsolai loses all state visibility.

### Mitigations

- **Heartbeat/watchdog**: Periodically poll `tmux capture-pane` (e.g., every 5s) and cross-check against hook-derived state. If the terminal shows a prompt character but state is `Working`, force a state reset to `Idle`.

- **State timeout**: If `Working` state persists for >5 minutes without any hook event, assume desync and probe the terminal.

- **Guard lambdas**: All `QTimer::singleShot` callbacks in yolo mode handlers should re-check `claudeState()` before acting. Current code does this in the fallback timer but not in the primary 500ms/1000ms singleShots.

- **Hook event sequence numbers**: Add a monotonic counter to hook events. If a gap is detected, Konsolai knows an event was dropped and can poll for recovery.

- **Stress test**: Before self-hosting, run a session that does rapid file reads/writes (e.g., `claude "read every .cpp file in src/"`) with all three yolo modes on, and verify state tracking stays accurate.

### Recommendation

Before developing Konsolai inside Konsolai:
1. Add the capture-pane watchdog (poll every 5s, cross-check state)
2. Add state re-check guards to all yolo timer callbacks
3. Run the stress test described above
4. Consider a "safe mode" that disables triple yolo if state tracking appears unreliable (e.g., no hook events received in 30s while tmux session is active)

---

## Token Budget Tracking

Token usage is the primary cost metric and the key optimization target once Konsolai can reliably "one-shot" apps from design documents. Tracking tokens per session enables evaluating prompt quality, comparing approaches, and budgeting.

### What to Track

Per session, per conversation:

| Metric | Source | Description |
|--------|--------|-------------|
| `input_tokens` | Claude API / CLI output | Tokens sent to Claude (prompts + context) |
| `output_tokens` | Claude API / CLI output | Tokens generated by Claude |
| `cache_read_tokens` | Claude API | Tokens served from prompt cache (cheaper) |
| `cache_creation_tokens` | Claude API | Tokens written to prompt cache |
| `total_cost_usd` | Computed | Estimated cost based on model pricing |
| `tool_use_count` | Hook events (PreToolUse) | Number of tool invocations |
| `prompt_count` | sendPrompt calls | Number of user/auto-continue prompts sent |
| `conversation_turns` | Derived | Round-trips (prompt → response) |
| `tokens_per_turn` | Derived | Average tokens per conversation turn |
| `context_window_usage` | Claude API | How full the context window is (%) |

### Where to Get Token Data

Claude Code CLI outputs token usage in its status line and in conversation metadata. Two approaches:

1. **Parse Claude CLI output**: `tmux capture-pane` and regex for token counts displayed in the Claude Code UI footer (e.g., `"Tokens: 45.2k in / 12.1k out"`). Fragile but requires no API access.

2. **Read conversation metadata**: Claude CLI stores conversation data in `~/.claude/projects/{hashed-path}/`. The `sessions-index.json` and individual conversation files contain token counts. `ClaudeSessionRegistry::readClaudeConversations()` already reads this data — extend it to extract token metrics.

3. **Hook events**: Extend the hook handler to capture token usage from Claude's `PostToolUse` and `Stop` events, which may include usage metadata. This is the most reliable source if Claude Code exposes it.

### Storage

- **Per-session counters**: Add to `ClaudeSession` as running totals, persisted in `sessions.json`
- **Time-series**: Optional SQLite database at `~/.local/share/konsolai/metrics.db` for historical analysis
- **Aggregates**: Daily/weekly rollups for dashboard display

### UI Surface Areas

1. **Status widget** (existing `ClaudeStatusWidget`): Show current session token count alongside state
2. **Session panel** (existing `SessionManagerPanel`): Token usage column in session list
3. **Android bridge**: `/api/sessions/{name}/token-usage` endpoint, `token_usage_updated` WebSocket event
4. **Android dashboard**: Token budget visualization — bar chart of tokens per session, cost estimate, trend over time

### Token Ergonomics

"Token ergonomics" measures how efficiently prompts convert into useful output. Key ratios to track:

- **Yield ratio**: `useful_output_tokens / total_tokens` — what fraction of tokens produced actual code/content vs. boilerplate, repeated context, or wasted exploration
- **One-shot score**: For design-doc-to-app workflows, `files_created / prompts_sent` — ideally approaching N files from 1 prompt
- **Context efficiency**: `cache_read_tokens / input_tokens` — higher means better prompt caching, less redundant context
- **Retry rate**: `total_prompts / successful_outcomes` — how many prompts it takes to get the desired result
- **Cost per file**: `total_cost_usd / files_modified` — amortized cost of each code change

### Design Document One-Shotting

The end goal: feed a single design document into Claude and get a working app out. Token tracking enables:

1. **Prompt template evaluation**: Compare token usage across different prompt structures for the same task. Track which templates produce the best yield ratio.
2. **Context window optimization**: Monitor when context fills up and Claude starts losing earlier context. This indicates when to split tasks or use conversation resume points.
3. **Model comparison**: Track the same design doc through different models (Sonnet vs Opus) and compare cost/quality tradeoffs.
4. **Budget alerts**: Set a token budget per session. Alert when 80% consumed. Auto-pause triple yolo at 95% to prevent runaway costs.
5. **Regression detection**: If a prompt template that used to one-shot a component now takes 3 turns, the token metrics will show the regression immediately.

### Implementation Priority

1. **Phase 1**: Parse token counts from `capture-pane` output + read from Claude conversation files. Display in status widget. Persist in `sessions.json`.
2. **Phase 2**: Extend hook handler to capture token metadata. Add to `ClaudeSession` as structured counters. Add to session panel.
3. **Phase 3**: SQLite time-series storage. Android bridge endpoint. Dashboard UI. Budget alerts.
4. **Phase 4**: Yield ratio computation. Prompt template A/B comparison tooling. One-shot scoring.

---

## Session Naming and Organization

As sessions proliferate (especially with self-hosting and one-shot workflows), the current naming scheme (`konsolai-{profile}-{8hex}`) will need extension:

- Tag sessions with the design doc or task they're working on
- Group sessions by project
- Track parent/child relationships (a session that spawns sub-sessions)
- Archive completed sessions with their token metrics for historical analysis

This is deferred but worth keeping in mind as the token tracking system is built.
